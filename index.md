# CS 4641 Project Proposal
 <img src = "https://raw.githubusercontent.com/Aaronwork1205/Machine_learning/gh-pages/assets/css/infographic_cropped1024_1.jpg"> 

## Introduction and background 

### Vehicle plate recognition system: 

The vehicle plate recognition system is used to recognize the vehicle plate number and store the information for parking charging.
### Background: 
The vehicle plate number recognition system is still limited and has low efficiency when handling cases, which includes but is not limited to event parking, regular permit parking illegal parking. This incapability often will incur the congestion of the main traffic route and increase the risk of traffic incidents. In order to improve the correctness of plate recognition and thus improve the vehicle throughput, we need a better model to handle the plate recognition and save unit labor cost.

## Methodology

 The dataset we will utilize is based on images of vehicle plates. To handle the influence of a variety of plates, the influence of different weather, lighting conditions, and the angle between the camera and the plate objects, at the very first step, we include the 53 images of plates from 50 States in America and 433 images of plates under different lighting conditions. 400 of these images will be served as the training dataset, and 33 of these images will be served as the test part. 
 
 We will consider each image as each data point and the features are the RGB color space and XY coordinates. Also, we will consider the testing part of the neural network as the target, which is also the goal that the model is aiming for. The target also includes the raw image data processing, which contains the processing of raw environments and angles from which the images were taken. Basically, the images were treated the same way as the training data, which is to be binarized and tiled to the same angle for the neural network to identify the plate number. The images include the plates with backgrounds like parking lots and traffic scenes.  We might also need to include more image datasets in the future if needed to encounter emerging challenges. The dataset is obtained through roboflow.com and Kaggle.com for academic purposes. Each image in the datasets has already been preprocessed, zipped and according cropped to be identical image size and small enough for training efficiency. In addition to the process data, we also have done dimensional reduction to make the image data small enough for fast iteration and processing. The dimensions for the raw image data are five, which are the RGB color space and the XY coordinates. By dimensional reduction, we have done binarization to the data, which abandons the RGB color space and only keeps the XY coordinates to retain the original image information to the greatest extent, which is only the plate number.
<img src="https://github.com/Aaronwork1205/Machine_learning/blob/gh-pages/assets/css/088e440f27b5949e977dc7310c0f8fe.png?raw=true" alt="" width = "450" height = "200"/>
<br> Further, we utilized the methods of unsupervised learning like Kmeans, DBSCAN, and GMM methods for us to better understand the datasets. For example, we need the unsupervised learning method to make clusters for us to better choose the right area, which contains vehicle plates. We might also incorporate pure plates for the supervised learning part to increase the detection accuracy further. <img src="https://github.com/Aaronwork1205/Machine_learning/blob/gh-pages/assets/css/6b9426131d837253eb06ed24db4a240.png?raw=true" alt="Methods" width="600" height="350"/> </div><br> The process will be divided into two parts to guarantee the performance of the recognition model, which are the training part and the test part. In the training dataset, we will train the model based on the label for each plate image. The test dataset mainly serves as the evaluation of the performance for the successful recognition rate. The new feature we will include in this project will be the involvement of deep learning technology. In the past decades, the vehicle plate recognition system is mainly based on the preprocessing of the captured plate images and identifying each character based on the character database. However, with the help of the deep learning method and enormous datasets, the process efficiency and correctness will be dramatically improved. The potential risk for this method includes failing to find a hyper parameter set to make the time cost in a reasonable range, and failing to improve the overall recognition rate based on the limited training and testing datasets at hand. It also might increase the data search and fetching budget to meet these accuracy criteria. A reasonable budget will include the usage of GPU with high performance and time searching for useful datasets. The basic estimate time for each epoch varies based on the size of each batch of datasets, and the configuration of each hyper parameter. It can range from several minutes to several hours to complete this task.



## Results

Our project focused on car plate recognition, which dataset consists of pixels of a given image. Due to this dataset's nature, each data point's features are RGB and XY coordinates. Feature selection is not applicable in our problem space since we must transform our features to binary values (black and white) and XY coordinates using preprocessing methods. However, we tried to run PCA on selected images.

The unsupervised learning methods we employed on the dataset are K-means, GMM, and DBSCAN.

[K-means image], [GMM image], [DBSCAN image].

By comparing the results, we can see that the DBSCAN method yields the best result. That is because K-means and GMM algorithms rely on calculating the distance between each data point and the center of each cluster. However, due to the unregular shapes resulting from preprocessing, the messiness of the positioning of clusters, and the uncertainty of the number of clusters, K-means and GMM algorithms did not yield satisfactory results. Sometimes K-means and GMM will produce weird clustering result, and it highly depends on pre-selecting the best number of clusters.

However, since the DBSAN algorithm relies on grouping the data points right next to each other, it works well on our problem. As we can see from the plot, DBSCAN algotithm will produce uncentern number of clusters, however, one of them will be the number plate. The black pixels of the number plate (blank places will no number is present) are all connected. As a result, the DBSCAN algorithm is capable of grouping the adjacent black pixels, and one of the clusters is the cluster of our plate. However, DBSCAN heavily relies on preproccessing, making sure that then number plate will be a clear and solid quadrilateral, not diated to make the boundaries unclear. So, with every aspect combined, DBSCAN is the best-performing algorithm.


### Discussion
 
#### Unsupervised learning methods (density estimation, clustering, etc)

Since the input data points are the pixels from the binary image, the data points are distributed to capture the shapes from the original image, such as the front/rear bumper, headlights, and windshields, as well as the license plate. All other areas are primarily white and will be ignored by the algorithm. Most preprocessed images contain the area of the license plate that is isolated from other subjects, in other words, there is a recognizable boundary around the plate. 

For evaluating the resulting clusters, serval characteristics are looked at. The length and width ratio is one of the characteristics of interest because the cluster of the plate usually has the ratio within a certain range. The target cluster contains significantly more points than other clusters, suggesting by results from 10 images. Comparing the percentages of points in the cluster will help shrink all raw results into a few clusters that likely contain the target. To further narrow down the clusters, Beta-CV measures are used to compute how each cluster is isolated from the others. As mentioned above, the target cluster, the plate, has a clear boundary to all its nearby shapes or clusters. Also, the target is primarily black and has a higher density than all other clusters. Based on the two distinctions, the Beta-CV measure will mostly likely correctly identify the target cluster as it computes the ratio of mean intracluster distance to the mean intercluster distance. 

By comparing the accuracy of the final results by GMM and DBSCAN, DBSCAN is clearly the method with the best performance. The plateâ€™s data points appear to be a rectangle or trapezoid on the binary image and are located next to each other with no gap in between. In most cases, the GMM algorithm tries to cluster the data points in elliptic shapes, because the nature of GMM is to find and fit data points onto gaussian distributions in the same dimensional space as the features. Therefore, the GMM algorithm cannot accurately recognize shapes like rectangles or trapezoids and it usually includes much more excessive and unnecessary points outside the plate or split the plate into multiple clusters in other cases. On the other hand, DBSCAN is more effective on the data points. The result generated by DBSCAN mostly consists of clusters of shapes that could be recognized by eye and found on the original image. Unlike GMM splitting a shape into different clusters, DBSCAN includes an entire shape into one cluster. DBSCAN connects points on a density and distance basis so that it can cluster points together that are closely located which makes it able to detect arbitrarily-shaped clusters and robust to noise. Therefore, the rectangle-like plate can be easily identified by DBSCAN. 




